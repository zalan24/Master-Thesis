Get a triangle on screen:
    ☐ Command buffer pool
        ✔ Initialize in engine @done (1/20/2021, 12:25:34 AM)
        ☐ CommandBuffer circulator:
            ✔ Only resetable one-time-submit command buffer are supported @done (1/22/2021, 9:25:39 PM)
            ✔ Is assigned to a family @done (1/22/2021, 9:25:43 PM)
            ✔ Have a Command pool @done (1/22/2021, 9:25:43 PM)
            ✔ The idea is that, upon cmd buffer request @done (1/22/2021, 9:25:46 PM)
                ✔ If there is an available buffer, return it @done (1/22/2021, 9:25:46 PM)
                    ✔ Prefer queues with lower index @done (1/22/2021, 9:25:47 PM)
                ✔ If not, create more command buffers @done (1/22/2021, 9:25:51 PM)
                ☐ If utilization is low for a long time, decrease the size by releasing the last X command buffers
            ✔ Upon recording the buffer, it should be sent to the execution thread with the circulator ptr @done (2/28/2021, 3:48:51 PM)
            ✔ Upon submission, give the pending buffer back to the circulator @done (2/28/2021, 3:48:53 PM)
            ✔ Dtor/close asserts/waits if there are some pending queues (that might be a problem when in a catch block...) @done (2/28/2021, 3:48:57 PM)
        ✔ Have a CommandBuffer circulator for each queue family @done (1/22/2021, 9:26:05 PM)
    ✔ Execution queue @done (2/28/2021, 3:49:10 PM)
        ✔ Create a struct which can store: (in union?) @done (1/27/2021, 10:20:31 PM)
            ✔ CommandBuffer handle @done (1/27/2021, 10:20:31 PM)
            ✔ std::function @done (1/27/2021, 10:20:32 PM)
            ✔ messages? @done (1/27/2021, 10:20:32 PM)
        ✔ Create a concurrent dequeue for this struct between recording and execution @done (1/27/2021, 10:20:34 PM)
        ✔ Execution is reading this pipe for instructions @done (1/27/2021, 10:20:36 PM)
        ✔ Execute command buffers @done (2/28/2021, 3:49:09 PM)
    ☐ Command for reset command buffer
    ☐ Add a new thread for callbacks
        ☐ Pair of fences or events + std::function can be added to it
        ☐ Wait for fence/event execute function
    ☐ Shader manager
    ☐ Finish descriptors
    ☐ Resource tracking
        ☐ Image and buffer tracking info
            ✔ Images and buffers need a separate struct under vulkan api @done (3/13/2021, 8:48:37 PM)
            ☐ This struct needs to store tracking slots
                ✔ These are for parallel state tracking @done (3/13/2021, 8:48:44 PM)
                ☐ Values stored per slot
                    ✔ Common @done (3/15/2021, 5:42:10 PM)
                        ✔ Ownership @done (3/9/2021, 2:53:36 PM)
                        ✔ Usable stages (src for prev barrier) @done (3/10/2021, 11:34:17 AM)
                        ✔ Event to wait on before usage???? @done (3/15/2021, 5:42:08 PM)
                            ✔ Command buffer recorder needs to keep track of used events (for garbage collection) @done (3/15/2021, 5:42:07 PM)
                    ✔ Images store data per mip level per array index (have max values for this) @done (3/11/2021, 9:20:12 PM)
                        ✔ Layout @done (3/10/2021, 9:00:26 AM)
                        ✔ Ongoing writing pipeline stages (src mask for next barrier) @done (3/9/2021, 2:55:48 PM)
                        ✔ Ongoing reading pipeline stages (src mask for next barrier for writing operations) @done (3/9/2021, 2:55:48 PM)
                        ✔ Ongoing flushing pipeline stages @done (3/9/2021, 2:55:49 PM)
                        ✔ Ongoing invalidating pipeline stages @done (3/9/2021, 2:55:50 PM)
                        ✔ Dirty access mask for availability (which access types have un-flushed memory) @done (3/9/2021, 2:57:24 PM)
                        ✔ Visibility access mask (which access types have un-flushed memory) @done (3/9/2021, 2:57:24 PM)
                        ✔ Upon writing @done (3/10/2021, 11:19:54 AM)
                            ✔ Requirements @done (3/10/2021, 10:47:39 AM)
                                ✔ Wait on flushing and invalidating stages if they are not 0 @done (3/10/2021, 10:40:35 AM)
                                ✔ Need to wait on other writes and reads (ongoing operations) @done (3/10/2021, 10:41:15 AM)
                                ✔ Correct ownership or shared access @done (3/10/2021, 10:47:36 AM)
                                ✔ Proper layout @done (3/10/2021, 10:43:45 AM)
                                ✔ Overwritten writes could be logged here for performance improvement suggestions @done (3/10/2021, 10:42:25 AM)
                            ✔ dirty access mask := writing access mask @done (3/10/2021, 10:50:00 AM)
                            ✔ Visibility mask := 0 (Memory not visible on any access type) @done (3/10/2021, 10:50:18 AM)
                            ✔ Ongoing writing := to current stages @done (3/10/2021, 10:51:28 AM)
                            ✔ Ongoing reading := 0 @done (3/10/2021, 10:51:29 AM)
                            ✔ Ongoing flushing := 0 @done (3/10/2021, 10:51:29 AM)
                            ✔ Ongoing invalidations := 0 @done (3/10/2021, 11:16:47 AM)
                            ✔ Set layout if it's changed @done (3/10/2021, 10:52:16 AM)
                        ✔ Upon reading @done (3/10/2021, 11:04:10 AM)
                            ✔ Requirements @done (3/10/2021, 11:01:21 AM)
                                ✔ Need to wait on invalidating operations @done (3/10/2021, 10:55:08 AM)
                                ✔ Dirty access mask for visibility & currentMask = currentMask (implies availability) @done (3/10/2021, 11:01:03 AM)
                                ✔ Correct ownership or shared access @done (3/10/2021, 10:57:56 AM)
                                ✔ Proper layout @done (3/10/2021, 11:01:20 AM)
                            ✔ Ongoing reading pipeline stages |= current stages @done (3/10/2021, 11:04:09 AM)
                        ✔ Upon inserting pipeline barrier @done (3/11/2021, 7:47:21 PM)
                            ✔ Parameters @done (3/11/2021, 7:36:07 AM)
                                ✔ Does it need to flush @done (3/11/2021, 7:36:04 AM)
                                ✔ Required visibility mask @done (3/11/2021, 7:36:05 AM)
                                ✔ Dst stages @done (3/11/2021, 7:36:05 AM)
                                ✔ Layout transition @done (3/11/2021, 7:36:06 AM)
                                ✔ Ownership transition @done (3/11/2021, 7:36:06 AM)
                            ✔ Handle usable mask @done (3/11/2021, 7:53:07 AM)
                            ✔ If it flushes the memory (needs to flush all access types) @done (3/11/2021, 7:45:05 AM)
                                ✔ src stages := ongoing writing stages @done (3/11/2021, 7:44:29 AM)
                                ✔ Ongoing flushing := dst stages @done (3/11/2021, 7:44:30 AM)
                                ✔ Src access mask := Dirty access mask for availability @done (3/11/2021, 7:44:43 AM)
                                ✔ Dirty access mask for availability := 0 @done (3/11/2021, 7:44:54 AM)
                                ✔ Ongoing invalidations := 0 @done (3/11/2021, 7:44:55 AM)
                            ✔ If it invalidates cache @done (3/11/2021, 7:54:20 AM)
                                ✔ Src := ongoing flushing stages OR writing stages (if it's the same barrier) @done (3/11/2021, 7:53:54 AM)
                                ✔ Ongoing invalidations |= dst stages @done (3/11/2021, 7:53:57 AM)
                                ✔ Dst access mask for pipeline barrier := required visibility mask & Dirty access mask for visibility @done (3/11/2021, 7:54:08 AM)
                                ✔ Dirty access mask for visibility ^= Dst access mask for pipeline barrier @done (3/11/2021, 7:54:18 AM)
                        ✔ Pay attention to memory layout (probably array index should be the first index, 2nd should be the mip level) @done (3/10/2021, 12:03:27 PM)
                    ☐ Buffer????
                        ☐ Have a small history of sub+resource ranges + an extra fix slot for the entire buffer (instead of arrays and mip levels)
                        ☐ Per history/fixed slot
                            ☐ A slot stores sub-resource ranges (with a fixed max number)
                            ☐ When doing on operation, find the correct slot:
                                ☐ If there is an exact match, use that
                                ☐ If not, try to create a new slot
                                ☐ If no more free slots, create a virtual slot and perform a slot merge
                            ☐ Do the exact same as for the image without the layout
                        ☐ History management
                            ☐ When accessing a slot, merge all overlapping slots into it (if the fixed slot is updated, history is cleared)
                        ☐ Slot merge
                            ☐ Calculate resulting sub-resource ranges
                                ☐ If the new slots needs to many ranges, merge the ranges
                            ☐ Find all slots in the history than conflict with this slot...
                            ☐ ... ???
                ✔ Most of the state data should be in a struct that is used by both the image and the buffer @done (3/10/2021, 1:15:36 PM)
                ✔ There is a fixed number of slots (use a define for this, could be a build option) @done (3/10/2021, 1:15:41 PM)
                ✔ Slot ids are acquired from the driver (not the resource) @done (3/10/2021, 9:26:28 AM)
                    ✔ A tracking slot = resource tracker object @done (3/10/2021, 1:37:12 PM)
                    ✔ The framegraph can reuse trackers, where there is no parallel usage (must be same queue as well) @done (3/18/2021, 9:25:14 AM)
                    ✔ Reuse as much as possible @done (3/18/2021, 9:25:14 AM)
                ☐ Placing barriers
                    ✔ Auto placed barriers: @done (3/12/2021, 9:12:28 AM)
                        ✔ Separate access function into validation and execution @done (3/11/2021, 8:44:33 PM)
                        ✔ Validation should be called before execution and it should create a pipeline barrier if necessary @done (3/12/2021, 9:12:27 AM)
                        ✔ If needed use the existing memory_sync function(s) @done (3/11/2021, 9:12:18 PM)
                        ✔ Execution will now only apply the new state, assuming correct resource state @done (3/11/2021, 9:12:25 PM)
                    ✔ Barriers are collected until the next access operation or the end of recording instead of immediate placement @done (3/17/2021, 10:36:23 AM)
                        ✔ Collect barriers per sub-resource range @done (3/13/2021, 8:48:06 PM)
                            ✔ Add some barriers states data to tracker @done (3/13/2021, 8:44:39 PM)
                        ✔ When a accessing the memory (or syncing?) flush barriers for the required sub-resource ranges @done (3/17/2021, 10:25:08 AM)
                            ✔ In this case, there should be an array of flushable barriers @done (3/13/2021, 8:45:03 PM)
                            ✔ When processing a new sub-resource range and a barriers is required for it, try to append it to one of the existing barriers or create a new barrier @done (3/13/2021, 8:45:18 PM)
                                ✔ Different barriers should be disjunct in terms dst and src stages @done (3/13/2021, 8:45:18 PM)
                        ✔ There should be special flush at the end of recording of a command buffer, that flushes everything in an optimized way @done (3/17/2021, 10:36:19 AM)
                    ✔ Create an enum of possible resource usages (separate for buffer and texture?) @done (3/12/2021, 9:08:10 AM)
                        ✔ Have a mapping from usage -> (pipeline stage mask, memory access mask) @done (3/12/2021, 9:08:09 AM)
                    ✔ Barriers are originally created for sub-resource ranges (later can be merged) @done (3/13/2021, 8:45:34 PM)
                    ✔ Barriers for a single sub-resource are merged @done (3/13/2021, 8:45:37 PM)
                    ☐ Barriers are flushed when accessing the memory (or doing a layout transition / ownership transfer)
                        ✔ Different layout transitions would need separate barriers @done (3/13/2021, 8:46:03 PM)
                        ☐ These could be merged with layout transition if the flushed barriers don't have a layout transition
                    ☐ Create a cmd for memory barrier
                        ☐ Input
                            ✔ Required usages @done (3/12/2021, 9:59:38 AM)
                            ✔ Resource & sub-resources @done (3/12/2021, 10:02:20 AM)
                            ☐ Ownership (could be deduced from current queue)
                            ✔ Layout transition for images (could be deduced from usage) @done (3/12/2021, 10:49:08 AM)
                        ✔ Resource needs to have a clear state regarding the selected usages @done (3/13/2021, 8:46:57 PM)
                        ✔ cmd pipeline barrier should not be exposed to the engine @done (3/12/2021, 9:58:50 AM)
                ☐ When submitting the command buffer with semaphores, states might be changed??? or not
            ☐ Sync by framegraph (registered resources)
                ✔ Try to reuse tracking ids as much as possible @done (3/18/2021, 9:25:33 AM)
                ☐ For same tracking id usage, with cpu dependency, use empty resource initializers for shared resources (enq dep implied, tracking info ok)
                ☐ For other nodes with same queue
                    ☐ Enq dep is implied, so normal barriers can be used. Declare a state object somewhere and auto use it
                    ☐ Consider using an event though (maybe optional auto event?)
                ☐ For other nodes with different queue
                    ☐ Declare basic states (layout only???)
                    ☐ Auto create semaphore based state objects and use them
                ☐ In same queue and different queue case, one (partial) state is declared by the user, the in/out states are generated to be valid

        ☐ Track resources globally
            ☐ Two submissions (= single command buffer submission) are conflicting if
                ☐ They have a common subresource usage
                ☐ Either the usage is conflicting or submissions are done a separate families while the resource is not shared
                ☐ If they don't have logical dependency, just mutual exclusion is required, then the no ordering is required
                    ☐ There are 3 kinds of async usage modes: non-conflicting usage, exlusive usage, ordered usage
            ☐ Submissions (= command buffers) will need an id inside the node they are submitted in
            ☐ Create a new flag in features to enable submissions sync validation
                ☐ Error on no sync
                ☐ ??? warning on unnecessary sync ???
            ☐ Execution queue needs to know which subresources are used for what in each submissions (layout transition = read/writer operation)
            ☐ Add new stuff to subresource state
                ☐ One writing queue
                ☐ Several reading queues
            ☐ Sync between submissions (semaphore or event) is required if they are not non-conflicting and they are not consecutive submissions on the same queue
            ☐ A submission needs to know:
                ☐ If other queues wait on it (if so, signal a semaphore at submission)
                ☐ What subresources will need sync in later submissions on the same queue (create an event for these)
                ☐ Which submissions to wait on (wait on there semaphore and assure consistency with their semaphore signalling)
                ☐ What events to wait on for what subresources (wait on these when accessing the resource)
            ☐ Resource tracking needs to handle signalled and waited semaphores and events
            ☐ Execution queue detects two conflicting submissions: A, B (even if they are synced based on cache)
                ☐ If A and B are order independent (conflict due to ownership)
                    ☐ If they have enqueue order dep
                        ☐ Save in cache, that they need sync (+ autosync if needed)
                    ☐ If they don't have enqueue order dep
                        ☐ Auto sync them in existing order
                        ☐ Add a warning to have enqueue dependency between these submissions
                ☐ If they are ordered (conflict due to conflicting usage)
                    ☐ If the nodes don't have queue dependency and they are on different queues
                        ☐ Error at least for debug mode. Otherwise assume current order to be correct and apply auto sync
                    ☐ If they are in same order as dependency (B depends on A)
                        ☐ Save in cache, that they need sync (+ autosync if needed)
                    ☐ If they are not in order => they are on different queues (A depends on B)
                        ☐ What now???????
            ☐ Plan
                ✘ Add auto enqueue order dep to any queue dependencies @cancelled (6/16/2021, 10:59:11 AM)
                ✔ Add submission id (eg. hash of name) @done (6/16/2021, 11:41:18 AM)
                    ✔ It's bound to a queue, it cannot be submitted anywhere else @done (6/16/2021, 11:01:21 AM)
                ✔ Add new state data to res state @done (6/18/2021, 10:17:00 AM)
                    ✔ Main queue + submission id + frame id + is_write @done (6/18/2021, 10:16:57 AM)
                    ✔ Add a set of reading queue + submission id + frame id + reading stages @done (6/18/2021, 10:16:59 AM)
                ✔ Command buffer needs to know if resource has been written (including layout transform) @done (6/18/2021, 10:32:02 AM)
                ✔ Identify which submissions need sync objects @done (6/19/2021, 1:13:16 PM)
                    ✔ Validate resource usage compared to framegraph too (framegraph queue can be resolved from queue + submission id) @done (6/19/2021, 1:13:12 PM)
                        ✔ Framegraph needs to be able to decide this even if the dependency is transitive @done (6/19/2021, 1:13:14 PM)
                    ✔ Semaphore is needed for conflicting usages on different queues @done (6/19/2021, 11:39:38 AM)
                        ✔ At submission, append mask of 0 to required semaphore stages @done (6/19/2021, 11:21:33 AM)
                        ✔ At dependency, append used mask to semaphore stages @done (6/19/2021, 11:39:36 AM)
                        ✔ Use tend to true when reading the cache @done (6/19/2021, 11:19:52 AM)
                        ✘ Cache should start at 0 @cancelled (6/19/2021, 11:02:32 AM)
                    ✘ Event is needed for conflicting usages on main queue only (on writing submission, the current queue is the main queue) @cancelled (6/19/2021, 11:02:25 AM)
                        ✘ If submissions doesn't happen consistently together, use semaphore instead (or nothing) @cancelled (6/19/2021, 11:02:28 AM)
                    ✔ Store where sync is needed in cache @done (6/19/2021, 11:21:47 AM)
                        ✔ At most one semaphore is needed per submission, but there can be multiple events @done (6/19/2021, 11:21:46 AM)
                    ✔ Create sync objects in submissions based on stats @done (6/19/2021, 11:23:09 AM)
                ☐ Deal with signal correction in framegraph
                    ✔ Create a special reusable command buffer for every queue family that waits on all previous work @done (6/20/2021, 12:17:45 PM)
                        ✔ Prepare a submission info struct that waits on everything (?in the engine?) @done (6/20/2021, 12:17:47 PM)
                    ✔ Clearing, which requires all work to be done @done (6/20/2021, 2:20:00 PM)
                        ✔ When a frame is fully done (all nodes finished), add the wait all cmd buffer to all used queues @done (6/20/2021, 2:19:35 PM)
                        ✘ Framegraph should have a function to retrive all semaphores used for waiting all work done @cancelled (6/20/2021, 2:19:47 PM)
                        ✔ Clearing garbage node should wait on all of these @done (6/20/2021, 2:19:54 PM)
                            ✔ Add a special dependency type for waiting on all work @done (6/20/2021, 2:19:53 PM)
                    ☐ QueueCpu dep for queries
                        ☐ QueueCpu dep implies dependency: submission -> cpu
                        ☐ acquiring such a node will require a list of sub-resources to wait on
                        ☐ Framegraph will need to acquire usages of the listed sub-resources and validate them
                            ☐ All usages must refer to either one of the waited gpu works, or something that has an enqueue dependency to any waited node
                        ☐ Record the need for a semaphore in the waited usages the same way as gpu-gpu work
                        ☐ Wait on the semaphores associated with the retrived usages (use auto sync if no semaphore is present)
                        ☐ Clean up old implementation (get rid of old semaphores used by it)
                ☐ Sync new states
                    ☐ Semaphore counter start from 0!!!!
                    ☐ If the src submissions had signal, use it. Otherwise auto create new signal
                        ☐ Wait on semaphore stages at the end of the signalling cmd buffer
                        ☐ Auto sync submissions needs a pipeline barrier that waits for all reading stages on the queue
                        ☐ src submissions's signal needs a pipeline barrier with all reading stages recorded in that cmd buffer. If it's not sufficient, auto sync is still required
                            ☐ Probably count these kinds of corrections in the report file separately from normal auto sync
                    ☐ Auto creation of signals should be in the report file
                    ☐ Need to implement syncing with event too. It could use cache to know what to use as dst stuff
                    ☐ Need to auto signal events, if they weren't signalled (what about unset?)
                ☐ Track new states
                    ☐ When sync object is applied, update main queue / states on reader queues
                    ☐ If no sync is needed, just update main queue normally, and update reading stages for reading queues
                    ☐ Existing sumbissions should consider state of the resource on that specific queue
                ☐ Test
                    ☐ Test queue->cpu dependency
                    ☐ Test separate queue families
                        ☐ with shared resources
                        ☐ with exclusive resources

        ☐ Track resources globally
            ☐ Created resource ids in the framegraph
                ☐ Resources are resolved in every frame (first usage of the res id)
                    ☐ Multiple physical resources can be bound to a res id (eg. images from gbuffer)
                ☐ Flag for last write (after which no sync is needed for read operations)???
                    ☐ Command buffer recorder should call a command to mark the last write
                    ☐ Intended to be used with Garbage system
                ☐ Flag for different resource every frame
                    ☐ No need to sync inter frame
                    ☐ This basically means the signalling of sync objects intended for the next frame
                ☐ Flag for global sub-resource range
                    ☐ When set, the sub-resource range is also recorded at resource resolution
                    ☐ Finer sync with events
                    ☐ Extra validation is needed
                ☐ No auto sync flag
                ☐ Special semaphore supplier
                    ☐ Instead of using the auto sync system, use a custom functor/something to know when and how to sync current resource usage
                    ☐ Intended for resources that are written only once (textures, meshes) and other custom resources
            ☐ Register the resource ids in the queue -> ... and ... -> queue dependencies
                ☐ Res id
                ☐ Read/write mask
            ☐ Validate registered resource usage
            ☐ Have a method in command buffer recorder for supplying a registered resource
                ☐ supplyRegisteredResource(resId, resource, sub_resource_range, pipelineStageMask, accessMask)
                ☐ signal semaphores and events based on dependencies in framegraph
                ☐ The exact event and semaphore should be known in the waiter commands (they might be recorded earlier)
            ☐ Have a method for demanding a registered resource
                ☐ demandRegisteredResource(resId, resource, sub_resource_range, pipelineStageMask, accessMask)
                ☐ This command buffer should wait on the proper semaphores and events
                ☐ Signal events and semaphores for writing nodes
            ☐ Maybe merge these two and add a mask for reading / writing???
            ☐ In case of a recorded usage of the resource doesn't conflict, there is no need to wait
            ☐ Once a resource is resolved by the supplier node, no sync is needed to different resource values (other image was used in the last frame)
            ☐ When waiting for a registered resource by event, just add it to the local tracker and it should do the work
            ☐ If there are no depending write operations for a resource, reads may not need to signal anything???
                ☐ Later frame writes can wait on frame finish instead???
            ☐ What about missing demand or supply operations???
        ☐ Validate resource usage
            ☐ Any resource
            ☐ Only debug mode
            ☐ Track resources globally in the framegraph (same way as in command buffer recorder)
            ☐ Use a mutex for recording usage history
            ☐ Find conflicting usages
            ☐ Allowed conflicting usage:
                ☐ Inside same node and same frame (need to register nodeId and frameId)
                ☐ Usage in a node/frame which has an appropriate dependency and the resource is registered
                    ☐ Need to check dependency offset and place of usage (cpu/queue)
        ☐ Validate synchronization using the link in sources
    ☐ Create an api consts header file and put all const values there (barrier limits, tracker limits, etc.)
    ✔ Add logging @done (3/28/2021, 12:39:53 PM)
    ✔ Discard image data using undefined oldLayout in transition (add a cmd for this, or add this to the barrier struct???) @done (3/13/2021, 7:52:00 PM)
    ☐ Check out "streamline trace": https://github.com/KhronosGroup/Vulkan-Samples/blob/master/samples/performance/render_passes/render_passes_tutorial.md
    ☐ Optimize push constant ranges: generate_resource_object() in compile.cpp
    ☐ Mesh shading: https://www.khronos.org/registry/vulkan/specs/1.2-extensions/man/html/VkPipelineInputAssemblyStateCreateInfo.html
    ☐ Specialization constants: https://www.khronos.org/registry/vulkan/specs/1.2-extensions/html/vkspec.html#pipelines-specialization-constants
    ☐ Sample shading (pipeline creation)
    ☐ Alpha coverage (pipeline creation)
    ☐ Depth bounds test (pipeline creation)
    ☐ Blend constants (pipeline creation)
    ☐ Color blending (pipeline creation)
    ☐ Debug markers: https://www.saschawillems.de/blog/2016/05/28/tutorial-on-using-vulkans-vk_ext_debug_marker-with-renderdoc/
        ☐ Actually use the VK_EXT_debug_utils for this: https://www.khronos.org/registry/vulkan/specs/1.1-extensions/pdf/vkspec.pdf#%5B%7B%22num%22%3A30297%2C%22gen%22%3A0%7D%2C%7B%22name%22%3A%22XYZ%22%7D%2C0%2C740.55%2Cnull%5D
    ☐ Performance queries: VK_KHR_performance_query
    ☐ Push constants
        ☐ Create a some system, where the position of headers can be specified
        ☐ Inside the scope of this system, these positions would be reserved for all shaders even if they don't use a header
    ☐ Check how command pool usages / family queue usages are synced. Maybe not necessary?
    ☐ Conditional rendering: https://www.khronos.org/news/permalink/tutorial-vulkan-conditional-rendering
    ☐ Sync
        ☐ Add command buffer recorder interface to api
        ☐ Separate tracking state from image (tracker should support decoupled tracking stats)
        ☐ Command buffers should have a garantee for each resource they are using and an auto calculated end result
        ☐ Submitting a command buffer will validate the garantees and apply the end states
        ☐ Images should have a single tracking state
        ☐ Remove tracking slots
        ☐ Execution queue should manage resource states (it should apply extra sync operations, if garantees are not met)
    ☐ Shaders
        ☐ Var types:
            ☐ Command buffer fix: values only defined within a command buffer, like grid cell transformation for grid rendering
            ☐ Material parameters: values set for a material, but not changed at runtime (usually, maybe for editing)
            ☐ Dynamic global variables: camera matrix for eg.
            ☐ Material resources (textures and buffers)
            ☐ Global resources
    ☐ Stages in framegraph
        ☐ Each node has a stage mask (simulation, pre-record, record, implicit enqueue, ?implicit execution?, each device queue...)
        ☐ Each stage has a frame counter (except queue stages)
        ☐ There is an implicit dependency between each stage of the node's execution
        ☐ Cpu-cpu dependencies will get a source and destination stage
        ☐ Command buffers will be recorded in the record stage only
        ☐ The record stage is meant to be a heavily dependent stage: depending on all previous nodes, that share resources
            ☐ This needs special validation
            ☐ Command buffers are recorded and submitted here
            ☐ It's meant to be a really fast stage, because command buffers rarely need to be re-recorded
        ☐ Each stage is autamatically synced with the begin stage marker of that stage (like the current start sime / start record markers, just automatic)
        ☐ The engine will need to trigger the stage markers using the built in stuff instead of custom nodes
        ☐ The record stage should have a function that initializes a command buffer recorder with all known resources from prev nodes + earlier cmd buffers from the current node
    ☐ drv::drv_assert shouldn't use std::strings, because it causes dynamic memory allocations...

Cleanup & other:
    ☐ Remove useless common driver stuff (drv/common)
    ✔ Use abstract driver class instead of function pointer table @done (1/26/2021, 11:31:13 AM)
    ✔ Maybe use a single large stack memory (thread local) instead of local ones: LOCAL_MEMORY_POOL_DEFAULT(pool)? @done (2/28/2021, 3:50:11 PM)


Questions:
    ✔ Query 16 queue and use 1 vs Query 1 queue and use 1 @done (1/18/2021, 12:28:09 PM)
        -> allocation cost
        -> can have extra perf cost as well. Don't do it
    ✔ Synchronize between two queue after every command (semaphores), but no actual waiting happens @done (1/18/2021, 12:28:30 PM)
        -> semaphore overhead is negligible
    ✔ 16 draw calls on 16 queues vs 16 draw calls on 1 queue (sync for depth test and sync for color write) @done (1/18/2021, 12:29:45 PM)
        -> no point in separation, card already runs in parallel. Set up render passes properly though
        -> cs and transfer can be separate
    ✔ How vk submit waits on semaphores, where stages are provided (command buffers might contain a lot of pipelines) @done (1/18/2021, 12:37:58 PM)
        -> all commands wait until that stage on the semaphore
    ✔ 100 commands on same buffer vs on separate buffers @done (1/18/2021, 12:29:18 PM)
        -> consumes memory / more api calls. Use a single buffer if possible
    ✔ Can I record commands to two separate command buffers, which share a command pool concurrently? @done (1/26/2021, 11:31:18 AM)
        -> No
    ☐ Transient command buffer vs non-transient (except for parallel execution)

    https://stackoverflow.com/questions/37575012/should-i-try-to-use-as-many-queues-as-possible

    ☐ Read: https://mynameismjp.wordpress.com/2018/06/17/breaking-down-barriers-part-3-multiple-command-processors/
    ☐ Read: https://community.arm.com/developer/tools-software/graphics/b/blog/posts/vulkan-mobile-best-practices-and-management


Resource identifiers
 * ???
Runtime stat object
 * Add structure to runtime stats (???)
    * Probably a map of resource id -> resource data
 * Add a feature flag for savig stats
 * Load / save stats (loading should consider which stats are required at runtime, only load those)
    * Save two files, one full, which is used when export stats is enabled (this will preserve previously collected data, used by shader compiler)
    * One for load only version, which only loads data, that's used in a prod version
 * Create a macro, that creates a recorder/reader object for the resource stats
 * Create a resource stat object for each command buffer automatically
Auto register resources
 * Instead of throwing an error, auto register unregistered resources based on the first access
    * Assume current ownership
    * Assume most optimal layout
    * Assume clean state (or whatever is required)
 * In a situation like this, record the current resource into the resource stats object
    * The dst state is as assumed here
    * The src state is found during execution
 * If exportation of runtime stats is enabled, add a resource usage stats object to the execution queue's command buffer data
    * The execution queue should record all resource usage into it (src usage)
External resources in render passes
 * Give a name to the render pass (and each subpass)
 * Create two resource stat objects per render pass
    * One for incoming resources
    * One for outgoing resources
 * When recording to cmd buffer, record attachment usage into the resource stats object
 * At the creation of render pass, create external dependencies based on usual usage
    * If unavailable, use something basic (auto pipeline barriers can fix it)
    * It's required to have some kind of an external barrier (at least for transitive dependency)