Get a triangle on screen:
    ✔ Rework command lanes @done (1/19/2021, 11:12:55 AM)
        ✔ Command lane info contains queue infos (name, what's required, what's preferred, priority, etc.) @done (1/19/2021, 10:42:42 AM)
        ✔ When using the same queue, use the highest priority @done (1/19/2021, 10:42:45 AM)
        ✔ Try to use different queue families in a command lane @done (1/19/2021, 10:45:02 AM)
        ✔ Command lane tries to get these queues separately if possible @done (1/19/2021, 10:45:21 AM)
        ✔ Command lane will have a set of queues assigned to the names, which don't have to be unique (transfer and render queue can be the same) @done (1/19/2021, 10:45:28 AM)
        ✔ Command lanes used in the engine: @done (1/19/2021, 10:45:36 AM)
            ✔ Main @done (1/19/2021, 10:45:36 AM)
                ✔ Render (graphics queue) @done (1/19/2021, 10:45:35 AM)
                ✔ Compute (compute queue) @done (1/19/2021, 10:45:35 AM)
                ✔ DtoH (transfer queue) @done (1/19/2021, 10:45:34 AM)
                ✔ HtoD (transfer queue) @done (1/19/2021, 10:45:33 AM)
            ✔ Input @done (1/19/2021, 10:45:33 AM)
                ✔ HtoD (transfer queue) @done (1/19/2021, 10:45:32 AM)
    ✔ Modify queue manager to work with command lanes @done (1/19/2021, 11:12:08 PM)
        ✔ Have a mapping of CommandLane -> QueueName -> Queue @done (1/19/2021, 11:12:08 AM)
        ✔ Acquired queues based on this @done (1/19/2021, 11:12:08 AM)
        ✔ Remove hash based groupings (maybe some other stuff as well) @done (1/19/2021, 11:12:07 PM)
    ☐ Create a frame memory allocator
        ☐ It needs to support allocation on recording thread and release in the execution thread (multiple frame memory objects?)
        ☐ Use a pool of frame mems? acquire in simulation thread, release in execution thread
    ☐ Command buffer pool
        ☐ Initialize in engine
        ☐ CommandBuffer circulator:
            ☐ Only resetable one-time-submit command buffer are supported
            ☐ Is assigned to a family
            ☐ Have a Command pool
            ☐ The idea is that, upon cmd buffer request
                ☐ If there is an available buffer, return it
                    ☐ Prefer queues with lower index
                ☐ If not, create more command buffers
                ☐ If utilization is low for a long time, decrease the size by releasing the last X command buffers
            ☐ Upon recording the buffer, it should be sent to the execution thread with the circulator ptr
            ☐ Upon submission, give the pending buffer back to the circulator
            ☐ Dtor/close asserts/waits if there are some pending queues (that might be a problem when in a catch block...)
        ☐ Have a CommandBuffer circulator for each queue family
    ☐ Rework frame graph
        ☐ Nodes will be assigned to specific queues
        ☐ Use frame mem
        ☐ Remove unnecessary stuff
        ☐ Reuse objects, where possible
        ☐ Single time nodes:
            ☐ They are given a single time command buffer from the circulator
            ☐ Execution removes executed dynamic nodes

        ☐ Static nodes
            ☐ Some nodes should be pre-created before recording starts (these should be fairly constant nodes)
            ☐ Don't create them every frame
            ☐ These nodes need the same queues every frame (until recreation)
            ☐ Nodes can have single-time submission (recorded every frame)
            ☐ Nodes can have a fixed command buffer. For such nodes, the renderer needs to have a function to fill them (before normal render)
                ☐ If they need recreating, add their command buffer to a separate list, paired with a fence, which is added to the assigned queue
                ☐ Have a cleanup thread (or use the callback wait thread), which waits for these fences and removes objects (later different types of resources can be added)

        ☐ Add extra info to dependencies? (for barriers and buffer grouping)
        ☐ Nodes should create command buffers directly and later record into them
            ☐ Nodes could have a list of command buffers??? (these would be in the same synchronization unit)
        ☐ Nodes should be assigned to a command lane
        ☐ Nodes need to be closeable (no more dependencies can be created)
        ☐ Allow partial execution of closed nodes
            ☐ Instead of actual execution, just return a queue and the command buffer
        ☐ Frame graph should be concurrent (adding nodes in one thread, partial executions in the other)
        ☐ Are semaphores needed within a single queue (events might be better)
    ☐ Implement barriers
    ☐ Implement timeline fences and semaphores
    ☐ Implement events
    ☐ Implement graphical pipeline
    ☐ Implement render pass
    ☐ Command for reset command buffer
    ☐ Add a new thread for callbacks
        ☐ Pair of fences or events + std::function can be added to it
        ☐ Wait for fence/event execute function
    ☐ Execute frame graph
        ☐ When a node is complete (closed):
            ☐ Have two command buffers (or two lists if lists are used)
            ☐ Wait for the execution buffer to be empty (executed)
            ☐ Swap buffer pointers
            ☐ Execution thread will execute the execution buffer and reset it, then signal the recorder thread, that the buffer is ready to swap
        ☐ Dynamic nodes: just remove them from frame graph and then execute
        ☐ Static nodes:
            ☐ constant nodes:
                ☐ Use transient command queues and just submit the same stuff every time
            ☐ one-time nodes:
                ☐ Use the command pool as in dynamic nodes
                ☐ Move the command buffer out of the node, execute at later
    ☐ Shader manager
    ☐ Finish descriptors

Cleanup & other:
    ☐ Remove useless common driver stuff (drv/common)
    ☐ Use abstract driver class instead of function pointer table


Questions:
    ✔ Query 16 queue and use 1 vs Query 1 queue and use 1 @done (1/18/2021, 12:28:09 PM)
        -> allocation cost
        -> can have extra perf cost as well. Don't do it
    ✔ Synchronize between two queue after every command (semaphores), but no actual waiting happens @done (1/18/2021, 12:28:30 PM)
        -> semaphore overhead is negligible
    ✔ 16 draw calls on 16 queues vs 16 draw calls on 1 queue (sync for depth test and sync for color write) @done (1/18/2021, 12:29:45 PM)
        -> no point in separation, card already runs in parallel. Set up render passes properly though
        -> cs and transfer can be separate
    ✔ How vk submit waits on semaphores, where stages are provided (command buffers might contain a lot of pipelines) @done (1/18/2021, 12:37:58 PM)
        -> all commands wait until that stage on the semaphore
    ✔ 100 commands on same buffer vs on separate buffers @done (1/18/2021, 12:29:18 PM)
        -> consumes memory / more api calls. Use a single buffer if possible
    ☐ Can I record commands to two separate command buffers, which share a command pool concurrently?
    ☐ Transient command buffer vs non-transient (except for parallel execution)

    https://stackoverflow.com/questions/37575012/should-i-try-to-use-as-many-queues-as-possible

    ☐ Read: https://mynameismjp.wordpress.com/2018/06/17/breaking-down-barriers-part-3-multiple-command-processors/
    ☐ Read: https://community.arm.com/developer/tools-software/graphics/b/blog/posts/vulkan-mobile-best-practices-and-management